Contains comments from authors about their solution after first investigation

1st Place 
  Sergey Zlobin:
      Решение основано на модели Yolo v5 от ultralytics.
      https://github.com/ultralytics/yolov5
      Внешние датасеты не использовались. Хотя, скорее всего, от них будет польза. Возможно, у меня, просто не было стимула поковырять внешние данные.
      1)     Так как люди на снимках очень маленькие, то я сразу решил делать детекцию окнами 1024x1024. Для обучения я разрезал каждую картинку на ~24 таких окон (по большей части непересекающихся – просто для ускорения обучения). Далее взял все (2950 штук) окна с боксами и некоторое количество безбоксовых окон (500 штук). Обучение производилось на 5 фолдах и разрешении 640.
      2)     Для инференса картинка разбивалась на несколько пересекающихся окон, и делалось предсказание с помощью модели из п.1. Слияние боксов пересекающихся окон делалось “ручным” способом аналогично NMS, только условие заменил на: площадь пересечения боксов более половины минимума площади из 2 боксов.
      при этом делалось еще одно предсказание на отраженной (Hor Flip) картинке. Ансамбль боксов делался по методу WBF:
      https://github.com/ZFTurbo/Weighted-Boxes-Fusion
      модель получила mAP 0.962 на лидерборде
      3)     После этого я добавить негативных примеров (вместо 500 стало 1366 штук). Причина - при визуальном просмотре не редкость False Positive. Также я увеличил разрешение обучения и инференса до 1024. Такая модель дала 0.968 на лидерборде.
      4)     После ансамбля моделей из пунктов 2 и 3 с весами 1:2 получил скор 0.975.
  Ivan
    Ага. Описание до меня не дошло, где-то потерялось по пути :man-walking:  Теперь более понятно, что такое 2 и 3 :slightly_smiling_face: А False руками добавлял?

  Sergey Zlobin
    Когда я разрезал исходные на окна, получилось довольно много картинок без боксов. Можно было бы их добавить ВСЕ в обучение, 
    но это сильно бы увеличило время обучения. Поэтому моя идея была взять только некоторые из пустых, на которых может быть что-то 
    похожее на детектируемый объект. Для этого я обучил вначале модель номер 1 на 1 фолде БЕЗ пустых картинок вообще, 
    и прогнал инференс на пустых изображениях. Отобрал те 500 из них, на которых нашлись самые уверенные боксы. Это nonempty.csv.
    Вторая версия  nonempty_p2.csv - это то же самое, но это я прогнал Model 2 (уже обученную с 500 пустыми боксами). 
    То, что лежит в csv это такая вероятность, вычисляемая по всем найденным боксам на картинке:
  ```
          is_empty = 1
          for label, score, location in test_locations[test_filename]:
              is_empty *= 1 - score
          non_empty_probs.append(1 - is_empty)
  ```
    Я не знаю, насколько важно было выбирать, такие картинки. Может было бы достаточно докинуть 2000 любых случайных пустых картинок, например.
    Насчет прода. Я не пытался оптимизировать скорость. Например, когда я разбиваю на окна я делаю инференс, то там по 1 окну передаются. 
    Думаю быстрее засовывать массив сразу батчами.
    
5th place 
  Ivan
    Ковыряюсь сейчас в https://github.com/vazhanio/Lacmus_5place  (собственно, оно самое простое с точки зрения потенциального заката в прод и нормально оформлено, чтобы воспроизвести).
    А именно - пробую заинферить с весами из гита, и отдельно затренить и потом заинферить. Во втором варианте метрики выходят хуже ощутимо
    |yolo5_5th_place_retrain				   | 1984,1984 |   0.9067  | 0.9466   | 0.6837   | 0.8732   | 0.9404   | |
    |yolo5_5th_place_git_weights               | 1984,1984 |   0.9578  | 0.9833   | 0.8192   | 0.9474   | 0.9799   | |
    Что-то делаю не так?

  Vazhanio
    А конфиг обучения совпадает( в части аугментаций?)
    Посмотрел по wandb ( там все параметры логируются)  параметры сети для тренировки точ в точ как у меня в репозитории и как скинули вы.

  Ivan  6:12 PM
  :thinking_alot:  Ну может, конечно, батч размером 8 всё так испортил, вроде такое может случатся (народ пишет). 
  Поиграюсь ещё с этим.  https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e
